{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nitin Mishra\\.virtualenvs\\Voice_Activated_Form_Assisstant-eTL7iws_\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "model_path = \"Models/ClassificationModel\"\n",
    "\n",
    "# Load the trained model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Amount\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    categories = [\"Name\", \"Phone Number\", \"Amount\", \"Account Number\"]\n",
    "    return categories[prediction]\n",
    "\n",
    "# Example Prediction\n",
    "example_text = \"Transfer 0 rupees to nitin\"\n",
    "print(\"Predicted Category:\", predict(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfoNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "DistilBertForSequenceClassification                     [1, 2]                    --\n",
       "├─DistilBertModel: 1-1                                  [1, 7, 768]               --\n",
       "│    └─Embeddings: 2-1                                  [1, 7, 768]               --\n",
       "│    │    └─Embedding: 3-1                              [1, 7, 768]               23,440,896\n",
       "│    │    └─Embedding: 3-2                              [1, 7, 768]               393,216\n",
       "│    │    └─LayerNorm: 3-3                              [1, 7, 768]               1,536\n",
       "│    │    └─Dropout: 3-4                                [1, 7, 768]               --\n",
       "│    └─Transformer: 2-2                                 [1, 7, 768]               --\n",
       "│    │    └─ModuleList: 3-5                             --                        42,527,232\n",
       "├─Linear: 1-2                                           [1, 768]                  590,592\n",
       "├─Dropout: 1-3                                          [1, 768]                  --\n",
       "├─Linear: 1-4                                           [1, 2]                    1,538\n",
       "=========================================================================================================\n",
       "Total params: 66,955,010\n",
       "Trainable params: 66,955,010\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 66.96\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 2.97\n",
       "Params size (MB): 267.82\n",
       "Estimated Total Size (MB): 270.79\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Create dummy input\n",
    "inputs = tokenizer(\"This is a test sentence\", return_tensors=\"pt\")\n",
    "\n",
    "# Use torchinfo to print summary\n",
    "summary(model, input_data=(inputs['input_ids'],), depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "\n",
    "\n",
    "# Common intro patterns (regex) to capture names after phrases\n",
    "INTRO_PATTERNS = [\n",
    "    r\"(?:this is|this's)\\s+([A-Z][\\w\\-]+(?:\\s+[A-Z][\\w\\-]+)*)\",\n",
    "    r\"(?:i am|i'm|im)\\s+([A-Z][\\w\\-]+(?:\\s+[A-Z][\\w\\-]+)*)\",\n",
    "    r\"(?:call me|friends call me|my name is)\\s+([A-Z][\\w\\-]+(?:\\s+[A-Z][\\w\\-]+)*)\",\n",
    "    r\"introduce myself\\s*,?\\s*i am\\s+([A-Z][\\w\\-]+(?:\\s+[A-Z][\\w\\-]+)*)\"\n",
    "]\n",
    "compiled_patterns = [re.compile(p, re.IGNORECASE) for p in INTRO_PATTERNS]\n",
    "\n",
    "def extract_names_spacy(text):\n",
    "    names = []\n",
    "\n",
    "    # 1) Rule-based regex patterns (high precision)\n",
    "    for pat in compiled_patterns:\n",
    "        for m in pat.finditer(text):\n",
    "            candidate = m.group(1).strip()\n",
    "            # Basic cleanup: strip trailing punctuation\n",
    "            candidate = re.sub(r'[\\.,;:!?\\)]*$', '', candidate)\n",
    "            names.append(candidate)\n",
    "\n",
    "    # 2) POS-based extraction using spaCy: consecutive PROPN tokens\n",
    "    doc = nlp(text)\n",
    "    prop_seq = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":\n",
    "            prop_seq.append(token.text)\n",
    "        else:\n",
    "            if prop_seq:\n",
    "                # join sequence and add if plausible (length > 1 char and more than 1 token or looks like a name)\n",
    "                candidate = \" \".join(prop_seq)\n",
    "                # avoid adding duplicates\n",
    "                if candidate not in names:\n",
    "                    names.append(candidate)\n",
    "                prop_seq = []\n",
    "    # flush\n",
    "    if prop_seq:\n",
    "        candidate = \" \".join(prop_seq)\n",
    "        if candidate not in names:\n",
    "            names.append(candidate)\n",
    "\n",
    "    # 3) Clean results: remove false positives (common words) - optional filter step\n",
    "    cleaned = []\n",
    "    for nm in names:\n",
    "        nm_clean = nm.strip()\n",
    "        # discard single-letter tokens or digits\n",
    "        if len(nm_clean) < 2: continue\n",
    "        if re.search(r'\\d', nm_clean): continue\n",
    "        cleaned.append(nm_clean)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kavita Reddy speaking', 'Kavita Reddy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_names_spacy(\"This is Kavita Reddy speaking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_regex(text):\n",
    "    import re\n",
    "\n",
    "    # Phone (Indian-style 10 digits, optional +91 or 0)\n",
    "    phones = re.findall(r'(?:(?:\\+91|0)?[\\s\\-]?)?[6-9]\\d{9}', text)\n",
    "\n",
    "    # Account numbers (usually 11 to 18 digits)\n",
    "    accounts = re.findall(r'\\b\\d{11,18}\\b', text)\n",
    "\n",
    "    # Amounts (₹, Rs., or plain numbers with commas/decimals)\n",
    "    amounts = re.findall(r'(?:₹|Rs\\.?|INR)?[\\s]?[0-9,]+(?:\\.\\d{1,2})?', text)\n",
    "\n",
    "    return {\n",
    "        \"phones\": phones[0],\n",
    "        \"accounts\": accounts[0],\n",
    "        \"amounts\": amounts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phones': ' 9876543210',\n",
       " 'accounts': '123456789012',\n",
       " 'amounts': [' 123456789012', '₹5,000', ' 123456789012', ' 9876543210']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_with_regex(\"account number 123456789012 Please transfer ₹5,000 to account number 123456789012 and call me at 9876543210\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: My name is Nitin Mishra and I live in Delhi.\n",
      "Extracted Names: ['Nitin Mishra']\n",
      "--------------------------------------------------\n",
      "Sentence: Barack Obama was the 44th President of the United States.\n",
      "Extracted Names: ['Barack Obama']\n",
      "--------------------------------------------------\n",
      "Sentence: Please connect me with Dr. A. P. J. Abdul Kalam.\n",
      "Extracted Names: ['A. P. J. Abdul Kalam']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_names(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    return names\n",
    "\n",
    "# Test sentences\n",
    "sentences = [\n",
    "    \"My name is Nitin Mishra and I live in Delhi.\",\n",
    "    \"Barack Obama was the 44th President of the United States.\",\n",
    "    \"Please connect me with Dr. A. P. J. Abdul Kalam.\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    print(f\"Sentence: {s}\")\n",
    "    print(\"Extracted Names:\", extract_names(s))\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Voice_Activated_Form_Assisstant-eTL7iws_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
